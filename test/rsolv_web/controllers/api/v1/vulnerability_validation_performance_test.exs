defmodule RsolvWeb.Api.V1.VulnerabilityValidationPerformanceTest do
  use RsolvWeb.ConnCase, async: false
  import Rsolv.APITestHelpers
  
  alias Rsolv.Cache.ValidationCache
  
  setup do
    # Clear cache before test
    ValidationCache.clear_all()
    
    # Get customer and API key from helper
    setup_api_auth()
  end
  
  @tag :performance
  test "cache improves performance for repeated validations", %{conn: conn, customer: customer, api_key: api_key} do
    # Create a large vulnerability
    large_content = Enum.map(1..100, fn i ->
      "function test#{i}() { console.log('Line #{i}'); }"
    end) |> Enum.join("\n")
    
    vulnerability = %{
      "id" => "perf-vuln",
      "patternId" => "js-eval-injection",
      "filePath" => "large.js",
      "line" => 50,
      "code" => "eval(userInput)",
      "severity" => "critical"
    }
    
    request_data = %{
      "vulnerabilities" => [vulnerability],
      "files" => %{
        "large.js" => large_content <> "\neval(userInput);\n" <> large_content
      }
    }
    
    # First request (cache miss)
    start_time1 = System.monotonic_time(:microsecond)
    conn1 = 
      conn
      |> put_req_header("x-api-key", api_key.key)
      |> put_req_header("content-type", "application/json")
      |> post("/api/v1/vulnerabilities/validate", request_data)
    json_response(conn1, 200)
    duration1 = System.monotonic_time(:microsecond) - start_time1
    
    # Second request (cache hit)
    start_time2 = System.monotonic_time(:microsecond)
    conn2 = 
      build_conn()
      |> put_req_header("x-api-key", api_key.key)
      |> put_req_header("content-type", "application/json")
      |> post("/api/v1/vulnerabilities/validate", request_data)
    json_response(conn2, 200)
    duration2 = System.monotonic_time(:microsecond) - start_time2
    
    # Cache hit should be significantly faster
    IO.puts("First request (cache miss): #{duration1}Î¼s")
    IO.puts("Second request (cache hit): #{duration2}Î¼s")
    IO.puts("Speed improvement: #{Float.round(duration1 / duration2, 2)}x")
    
    # Assert cache was used
    assert ValidationCache.get_stats()["cache_hits"] == 1
    assert ValidationCache.get_stats()["cache_misses"] == 1
    
    # Just verify cache behavior instead of timing (more stable)
    # The speed improvement logging above is still useful for debugging
    assert duration1 > 0
    assert duration2 > 0
  end
  
  @tag :performance
  test "batch processing with cache reduces redundant computations", %{conn: conn, customer: customer, api_key: api_key} do
    # Create 50 vulnerabilities with 25 duplicates
    vulnerabilities = Enum.flat_map(1..25, fn i ->
      vuln = %{
        "id" => "batch-#{i}",
        "patternId" => "js-eval-injection",
        "filePath" => "file#{rem(i, 5)}.js",  # Only 5 different files
        "line" => rem(i, 3) + 1,             # Only 3 different lines
        "code" => "eval(input#{rem(i, 2)})", # Only 2 different code patterns
        "severity" => "critical"
      }
      # Return each vulnerability twice
      [vuln, Map.put(vuln, "id", "batch-#{i}-dup")]
    end)
    
    files = Enum.reduce(0..4, %{}, fn i, acc ->
      Map.put(acc, "file#{i}.js", "// File #{i}\neval(input0);\neval(input1);\n")
    end)
    
    request_data = %{
      "vulnerabilities" => vulnerabilities,
      "files" => files
    }
    
    start_time = System.monotonic_time(:millisecond)
    
    conn = 
      conn
      |> put_req_header("x-api-key", api_key.key)
      |> put_req_header("content-type", "application/json")
      |> post("/api/v1/vulnerabilities/validate", request_data)
    
    response = json_response(conn, 200)
    duration = System.monotonic_time(:millisecond) - start_time
    
    # Should process all 50 vulnerabilities
    assert length(response["validated"]) == 50
    assert response["stats"]["total"] == 50
    
    # But should have significant cache usage for duplicates
    stats = ValidationCache.get_stats()
    IO.puts("\nBatch processing stats:")
    IO.puts("Total vulnerabilities: 50")
    IO.puts("Unique computations: #{stats["cache_misses"]}")
    IO.puts("Internal cache hits: #{stats["internal_hits"]}")
    IO.puts("Processing time: #{duration}ms")
    
    # We should have many internal hits due to duplicates
    assert stats["internal_hits"] > 20
  end
end