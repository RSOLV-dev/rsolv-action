# RSOLV Monitoring Health Report

**Date**: 2025-10-15
**Author**: System Audit
**Status**: ğŸŸ¡ Partially Functional - Requires Implementation

---

## Executive Summary

A comprehensive audit of the RSOLV monitoring infrastructure (Prometheus + Grafana) has been completed. The infrastructure is **deployed and operational**, but **RFC-060 validation metrics are not being emitted** because the telemetry instrumentation is missing from the backend code.

### Status Overview

| Component | Status | Details |
|-----------|--------|---------|
| **Prometheus** | âœ… Running | 1/1 pods healthy, uptime: 3d4h |
| **Grafana** | âœ… Running | 1/1 pods healthy, uptime: 3d1h |
| **Metrics Endpoint** | âœ… Working | `/metrics` accessible on port 4021 |
| **Prometheus Scraping** | âœ… Fixed | Port corrected (80 â†’ 4021) |
| **Alert Rules** | âœ… Loaded | RFC-060 alerts present in ConfigMap |
| **RFC-060 Metrics** | âŒ Not Emitting | Telemetry events not implemented |
| **Grafana Dashboard** | âš ï¸ Exists | Dashboard configured but no data |

---

## Issues Found and Fixed

### Issue 1: âœ… FIXED - Prometheus Scraping Wrong Port

**Problem**: Prometheus was configured to scrape RSOLV platform on port 80 (HTTP service) instead of port 4021 (metrics endpoint).

**Impact**: No RSOLV metrics being collected by Prometheus.

**Root Cause**:
```yaml
# BEFORE (incorrect):
- job_name: 'rsolv-platform'
  static_configs:
    - targets: ['rsolv-platform.rsolv-production.svc.cluster.local:80']

# AFTER (correct):
- job_name: 'rsolv-platform'
  static_configs:
    - targets: ['rsolv-platform.rsolv-production.svc.cluster.local:4021']
```

**Fix Applied**:
- Updated Prometheus ConfigMap (`prometheus-config` in `monitoring` namespace)
- Restarted Prometheus deployment to reload configuration
- Verified port 4021 is exposed on service with name `metrics`

**Verification**:
```bash
# Service ports confirmed:
- name: http
  port: 80
  targetPort: 4000
- name: metrics
  port: 4021
  targetPort: 4021

# Prometheus scrape annotations on pods:
prometheus.io/scrape: "true"
prometheus.io/port: "4021"
prometheus.io/path: "/metrics"
```

---

### Issue 2: âŒ CRITICAL - RFC-060 Telemetry Events Not Implemented

**Problem**: The PromEx ValidationPlugin is configured to listen for RFC-060 telemetry events, but **no code is emitting these events**.

**Impact**:
- RFC-060 Grafana dashboard shows no data
- RFC-060 Prometheus alerts cannot fire
- No visibility into validation/mitigation performance

**Root Cause Analysis**:

The `Rsolv.PromEx.ValidationPlugin` expects these telemetry events:
- `[:rsolv, :validation, :complete]` - Validation phase completion
- `[:rsolv, :validation, :test_generated]` - Test generation events
- `[:rsolv, :mitigation, :complete]` - Mitigation phase completion
- `[:rsolv, :mitigation, :trust_score]` - Trust score events

**Expected Metrics**:
```
rsolv_validation_executions_total{repo,language,framework,status}
rsolv_validation_test_generated_total{repo,language,framework}
rsolv_validation_duration_milliseconds{repo,language,framework}
rsolv_mitigation_executions_total{repo,language,framework,status}
rsolv_mitigation_trust_score_value{repo,language,framework}
```

**Current Reality**: Grep search shows **zero** instances of these events being emitted:
```bash
grep -r ":telemetry.execute.*validation.*complete" lib/
# No results found
```

**Why This Happened**:
1. RFC-060 validation happens in **GitHub Action** (frontend), not backend
2. Backend only provides **support APIs** (analyze, generate endpoints)
3. Telemetry instrumentation was designed but never implemented
4. PromEx plugin was created expecting events that don't exist

---

## Architecture Gap: Frontend vs Backend Metrics

### Current Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Action (RSOLV-action)     â”‚
â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  VALIDATE Phase             â”‚  â”‚
â”‚   â”‚  - Generates tests          â”‚  â”‚
â”‚   â”‚  - Runs validation          â”‚  â”‚
â”‚   â”‚  - No telemetry to backend  â”‚  â”‚â—„â”€â”€â”€ NO METRICS EMITTED
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  MITIGATE Phase             â”‚  â”‚
â”‚   â”‚  - Generates fixes          â”‚  â”‚
â”‚   â”‚  - Creates PRs              â”‚  â”‚
â”‚   â”‚  - No telemetry to backend  â”‚  â”‚â—„â”€â”€â”€ NO METRICS EMITTED
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ API Calls
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RSOLV Backend (Elixir/Phoenix)    â”‚
â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Test Integration APIs      â”‚  â”‚
â”‚   â”‚  - /analyze (scoring)       â”‚  â”‚
â”‚   â”‚  - /generate (AST)          â”‚  â”‚
â”‚   â”‚  - No telemetry emission    â”‚  â”‚â—„â”€â”€â”€ COULD EMIT METRICS HERE
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  PromEx ValidationPlugin    â”‚  â”‚
â”‚   â”‚  - Listening for events     â”‚  â”‚
â”‚   â”‚  - Never receives any       â”‚  â”‚â—„â”€â”€â”€ WAITING FOR EVENTS
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ /metrics endpoint
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Prometheus   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SCRAPES SUCCESSFULLY
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            BUT NO RFC-060 METRICS
```

### Options for Resolution

#### Option 1: Emit Telemetry from Backend APIs (Recommended)

**Approach**: Add telemetry emission in `TestIntegrationController` when `analyze` and `generate` endpoints are called.

**Pros**:
- Backend has all context (repo, language, framework)
- Metrics available immediately
- Centralized monitoring
- Works for all Git forges (not just GitHub)

**Cons**:
- Only tracks API usage, not full validation workflow
- Won't capture retry attempts, test failures, or PR creation
- Missing frontend-specific metrics (e.g., Claude Code iterations)

**Implementation**:
```elixir
# lib/rsolv_web/controllers/api/test_integration_controller.ex
defmodule RsolvWeb.API.TestIntegrationController do
  # ...

  def analyze(conn, params) do
    start_time = System.monotonic_time(:millisecond)

    # ... existing analyze logic ...

    # Emit telemetry
    :telemetry.execute(
      [:rsolv, :test_integration, :analyze],
      %{duration: System.monotonic_time(:millisecond) - start_time},
      %{
        repo: params["vulnerableFile"],  # Extract repo from context
        language: params["language"],
        framework: params["framework"],
        status: "completed"
      }
    )

    # Return response
  end

  def generate(conn, params) do
    start_time = System.monotonic_time(:millisecond)

    # ... existing generate logic ...

    # Emit telemetry
    :telemetry.execute(
      [:rsolv, :test_integration, :generate],
      %{
        duration: System.monotonic_time(:millisecond) - start_time,
        lines_integrated: count_lines(result.integrated_content)
      },
      %{
        repo: params["repo"] || "unknown",
        language: params["language"],
        framework: params["framework"],
        method: result.method,  # :ast or :append or :new_file
        status: "completed"
      }
    )

    # Return response
  end
end
```

**Effort**: Low (2-4 hours)
- Add telemetry emission to 2 controller actions
- Update PromEx plugin to listen for new events
- Test and verify metrics appear

#### Option 2: Push Metrics from GitHub Action

**Approach**: Have GitHub Action push metrics to backend via dedicated API endpoint after validation/mitigation completes.

**Pros**:
- Complete workflow visibility (includes retries, failures, PR creation)
- Captures frontend-specific metrics (Claude Code iterations, test execution results)
- True validation/mitigation metrics (not just API usage)

**Cons**:
- More complex implementation
- Requires new API endpoint
- Authentication and authorization needed
- Potential for metrics loss if API call fails

**Implementation**:
```typescript
// RSOLV-action/src/telemetry/backend-reporter.ts
export class BackendTelemetryReporter {
  async reportValidation(data: {
    repo: string;
    issue: number;
    language: string;
    framework: string;
    status: 'completed' | 'failed';
    duration_ms: number;
    tests_generated: number;
    claude_iterations: number;
  }) {
    await fetch(`${this.apiUrl}/api/v1/telemetry/validation`, {
      method: 'POST',
      headers: {
        'x-api-key': this.apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(data)
    });
  }

  async reportMitigation(data: {
    repo: string;
    issue: number;
    language: string;
    framework: string;
    status: 'completed' | 'failed';
    duration_ms: number;
    trust_score: number;
    pr_created: boolean;
  }) {
    await fetch(`${this.apiUrl}/api/v1/telemetry/mitigation`, {
      method: 'POST',
      headers: {
        'x-api-key': this.apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(data)
    });
  }
}
```

**Effort**: Medium (8-12 hours)
- Create new telemetry API endpoint in backend
- Implement authentication and validation
- Add telemetry reporter to RSOLV-action
- Integrate into validation-mode and mitigation-mode
- Test end-to-end
- Handle failures gracefully (don't block workflow if telemetry fails)

#### Option 3: Hybrid Approach (Best Long-Term)

**Approach**: Combine both options:
1. Backend emits metrics for API usage (Option 1)
2. Frontend pushes rich workflow metrics (Option 2)

**Pros**:
- Comprehensive visibility
- API metrics available immediately
- Workflow metrics provide deep insights
- Backend metrics work for all Git forges
- Frontend metrics specific to GitHub Actions

**Cons**:
- Most complex implementation
- Requires maintaining both systems

**Effort**: High (12-16 hours for complete implementation)

---

## Recommendation

**Immediate Action (Week 1)**: Implement **Option 1** (Backend API Telemetry)
- Quick win - get basic metrics flowing
- Low risk - contained to backend
- Provides value immediately for monitoring API usage
- Can be done without touching RSOLV-action

**Future Enhancement (Week 3-4)**: Implement **Option 2** (Frontend Push Metrics)
- More comprehensive metrics
- True validation/mitigation workflow visibility
- Aligns with RFC-060 monitoring goals

---

## Current Monitoring Infrastructure Status

### âœ… Working Components

1. **Prometheus Deployment**
   - Status: Healthy (1/1 pods running)
   - Uptime: 3 days 4 hours
   - Storage: Using PVC `prometheus-pvc`
   - Configuration: Auto-reloading on ConfigMap changes

2. **Grafana Deployment**
   - Status: Healthy (1/1 pods running)
   - Uptime: 3 days 1 hour
   - Authentication: Using `grafana-credentials` secret
   - Plugins: grafana-clock-panel, grafana-simple-json-datasource
   - Dashboard Provisioning: Enabled via ConfigMaps

3. **Metrics Endpoint**
   - URL: `http://rsolv-platform.rsolv-production.svc.cluster.local:4021/metrics`
   - Status: Accessible and returning metrics
   - Format: Prometheus exposition format
   - Metrics Count: 200+ metrics (BEAM, Phoenix, Ecto, Application)

4. **Prometheus Scraping**
   - Job: `rsolv-platform` (production)
   - Job: `rsolv-platform-staging` (staging)
   - Job: `kubernetes-pods` (dynamic pod discovery)
   - Scrape Interval: 15s
   - Evaluation Interval: 15s

5. **Alert Rules Loaded**
   - `application_alerts.yml` - High error rate
   - `business_alerts.yml` - Signup drop-off
   - `rfc060_alerts.yml` - **9 validation/mitigation alerts** âœ…
   - `ast-validation.rules` - AST validation (RFC-036)

6. **Alertmanager**
   - Status: Healthy (1/1 pods running)
   - Uptime: 74 days
   - Configuration: Ready to route alerts

### ğŸ“Š Available Metrics (Working)

**BEAM/Erlang VM Metrics**:
```
rsolv_prom_ex_beam_system_schedulers_info
rsolv_prom_ex_beam_system_memory_*
rsolv_prom_ex_beam_processes_*
rsolv_prom_ex_beam_ets_*
```

**Phoenix HTTP Metrics**:
```
rsolv_prom_ex_phoenix_http_request_duration_milliseconds
rsolv_prom_ex_phoenix_http_requests_total{method,path,status}
rsolv_prom_ex_phoenix_endpoint_*
```

**Ecto Database Metrics**:
```
rsolv_prom_ex_ecto_query_duration_milliseconds
rsolv_prom_ex_ecto_connections_*
rsolv_prom_ex_ecto_repo_*
```

**Application Metrics**:
```
rsolv_prom_ex_application_dependency_info{name,version,modules}
rsolv_prom_ex_application_git_sha_info
```

### âŒ Missing Metrics (Not Implemented)

**RFC-060 Validation Metrics** (Expected but not present):
```
rsolv_validation_executions_total{repo,language,framework,status}
rsolv_validation_test_generated_total{repo,language,framework}
rsolv_validation_duration_milliseconds_bucket{repo,language,framework}
rsolv_mitigation_executions_total{repo,language,framework,status}
rsolv_mitigation_trust_score_value_bucket{repo,language,framework}
```

---

## Grafana Dashboards

### Existing Dashboards

1. **System Dashboard** (`uid: system`)
   - CPU Usage by pod
   - Memory Usage by pod
   - Status: âœ… Working (generic Kubernetes metrics)

2. **Application Dashboard** (`uid: application`)
   - Total HTTP Requests
   - Average Request Duration
   - HTTP 5xx Errors
   - Total Conversions
   - Status: âœ… Working (Phoenix metrics)

3. **Business Dashboard** (`uid: business`)
   - Total Signups
   - Total Feedback Submissions
   - Signups Per Hour
   - Signups by Source
   - Status: âœ… Working (application-specific metrics)

4. **RFC-060 Validation Dashboard** (`uid: rfc-060-validation`)
   - Location: `/home/dylan/dev/rsolv/priv/grafana_dashboards/rfc-060-validation-metrics.json`
   - Configured: Yes
   - Working: âŒ **No data** (metrics not being emitted)
   - Panels:
     * Validation Success Rate
     * Validation Executions (24h)
     * Average Validation Duration
     * Validation Executions Over Time (by Status)
     * Validation Duration Distribution (p50, p95, p99)
     * Validation Executions by Language
     * Validation Executions by Repository
     * Failed Validations (Last 1h)
     * Validation Rate (executions/min)

### Dashboard Configuration

Dashboards are provisioned via ConfigMaps:
- `grafana-dashboards-config` - Dashboard provider configuration
- `grafana-dashboards` - System, Application, Business dashboards
- `signup-metrics-dashboard` - Early access signup metrics

RFC-060 dashboard is loaded from application code:
```elixir
# lib/rsolv/prom_ex.ex
def dashboards do
  [
    # ...
    {:otp_app, "grafana_dashboards/rfc-060-validation-metrics.json"}
  ]
end
```

---

## Alert Rules Status

### RFC-060 Alert Rules (Configured but Not Firing)

**Location**: `/home/dylan/dev/rsolv/config/prometheus/rfc-060-alerts.yml`
**Loaded in Prometheus**: âœ… Yes (via ConfigMap `prometheus-rules`)
**Status**: âš ï¸ Cannot fire (metrics not available)

**9 Alerts Configured**:

1. `ValidationSuccessRateLow` (WARNING) - Success rate < 50% for 15m
2. `ValidationSuccessRateCritical` (CRITICAL) - Success rate < 25% for 10m
3. `MitigationTrustScoreLow` (WARNING) - Trust score < 60 for 24h
4. `ValidationExecutionsStalled` (INFO) - No executions for 1h
5. `TestGenerationDurationHigh` (WARNING) - p95 > 30s for 20m
6. `TestExecutionDurationHigh` (WARNING) - p95 > 60s for 20m
7. `HighValidationFailureRateByRepo` (WARNING) - Failure rate > 50% for 30m
8. `MitigationDurationHigh` (WARNING) - p95 > 5min for 30m
9. `NoPRsCreated` (WARNING) - No PRs in 24h despite active validations

**Alert Routing**: Configured in example format (needs Alertmanager setup):
- Critical alerts â†’ PagerDuty
- Warning alerts â†’ Slack (#rfc-060-warnings)
- Info alerts â†’ Email (team@rsolv.dev)

### AST Validation Alert Rules (Working)

**Location**: `/home/dylan/dev/rsolv/RSOLV-infrastructure/shared/monitoring/prometheus-alerts-ast-validation.yaml`
**Status**: âœ… Loaded and functional (RFC-036 metrics are being emitted)

**7 Alerts**:
1. `LowFalsePositiveReduction` - Reduction < 70% for 1h
2. `SlowValidationResponse` - p95 > 100ms for 15m
3. `CriticalValidationLatency` - p95 > 500ms for 5m
4. `LowCacheHitRate` - Hit rate < 50% for 30m
5. `ValidationServiceDown` - Service unreachable for 5m
6. `HighValidationErrorRate` - Error rate > 5% for 10m
7. `PatternHighRejectionRate` - Specific pattern rejected > 50/hr

---

## Action Plan

### Immediate Actions (This Week)

1. **âœ… COMPLETED**: Fix Prometheus scrape configuration
   - Changed port from 80 to 4021
   - Restarted Prometheus
   - Verified metrics endpoint accessible

2. **ğŸ”² TODO**: Implement Backend API Telemetry (Option 1)
   - Add telemetry emission to `TestIntegrationController.analyze/2`
   - Add telemetry emission to `TestIntegrationController.generate/2`
   - Test with curl to verify events emitted
   - Verify metrics appear in Prometheus
   - Estimated effort: 2-4 hours

3. **ğŸ”² TODO**: Verify Metrics in Prometheus
   - Wait 1-2 minutes for scrape
   - Check Prometheus targets page
   - Query for `rsolv_test_integration_*` metrics
   - Verify data is being collected

4. **ğŸ”² TODO**: Test Grafana Dashboards
   - Access Grafana UI
   - Navigate to RFC-060 dashboard
   - Verify panels show data (even if limited)
   - Take screenshots for documentation

### Short-Term Actions (Next 2 Weeks)

1. **ğŸ”² TODO**: Enhance Backend Telemetry
   - Add more context to telemetry events (customer_id, issue_number if available)
   - Add error tracking (emit telemetry on failures)
   - Document telemetry schema

2. **ğŸ”² TODO**: Update PromEx Plugin
   - Add metrics for test-integration events
   - Update dashboard to show API usage metrics
   - Add new alert rules for API errors

3. **ğŸ”² TODO**: Create Test Suite
   - Write automated tests for telemetry emission
   - Verify all events have required metadata
   - Test Prometheus metric format

### Long-Term Actions (Next Month)

1. **ğŸ”² TODO**: Implement Frontend Push Metrics (Option 2)
   - Design telemetry API endpoint
   - Implement authentication
   - Add telemetry reporter to RSOLV-action
   - Integrate into validation/mitigation workflows
   - Test end-to-end

2. **ğŸ”² TODO**: Configure Alertmanager
   - Set up PagerDuty integration
   - Set up Slack integration
   - Test alert routing
   - Document on-call procedures

3. **ğŸ”² TODO**: Add Monitoring Documentation
   - Document available metrics
   - Create troubleshooting guide
   - Document alert response procedures
   - Add to operator runbooks

---

## Testing Procedure

### How to Generate Test Metrics (Once Implemented)

**Option A: Use Demo Repository**
```bash
# Trigger GitHub Action workflow on nodegoat-vulnerability-demo
cd nodegoat-vulnerability-demo
gh workflow run full-three-phase-test.yml \
  --ref main \
  -f max_issues=2 \
  -f api_url=https://api.rsolv.dev
```

**Option B: Direct API Testing**
```bash
# Test analyze endpoint
curl -X POST "https://api.rsolv.dev/api/v1/test-integration/analyze" \
  -H "x-api-key: rsolv_GD5KyzSXvKzaztds23HijV5HFnD7ZZs8cbF1UX5ks_8" \
  -H "Content-Type: application/json" \
  -d '{
    "vulnerableFile":"app/controllers/users_controller.rb",
    "vulnerabilityType":"SQL injection",
    "candidateTestFiles":["spec/controllers/users_controller_spec.rb"],
    "language":"ruby",
    "framework":"rspec"
  }'

# Wait 15 seconds for Prometheus scrape

# Check metrics
kubectl exec -n rsolv-production rsolv-platform-6cc9988457-48b9q -- \
  curl -s http://localhost:4021/metrics | grep rsolv_test_integration
```

### How to Verify Monitoring is Working

1. **Check Prometheus Targets**
   ```bash
   kubectl port-forward -n monitoring svc/prometheus-service 9090:9090 &
   open http://localhost:9090/targets
   # Look for "rsolv-platform" job - should be "UP" with green status
   ```

2. **Query Prometheus**
   ```bash
   # Check if metrics exist
   curl "http://localhost:9090/api/v1/query?query=up{job='rsolv-platform'}"

   # Once implemented, check RFC-060 metrics
   curl "http://localhost:9090/api/v1/query?query=rsolv_validation_executions_total"
   ```

3. **Check Grafana Dashboard**
   ```bash
   kubectl port-forward -n monitoring svc/grafana-service 3000:3000 &
   open http://localhost:3000
   # Login with credentials from grafana-credentials secret
   # Navigate to Dashboards â†’ RFC-060 Validation Metrics
   ```

4. **Check Alert Rules**
   ```bash
   # View loaded rules
   curl "http://localhost:9090/api/v1/rules" | jq '.data.groups[] | select(.name | contains("rfc_060"))'
   ```

---

## Configuration Files Reference

### Prometheus Configuration
**File**: `RSOLV-infrastructure/shared/monitoring/base/prometheus.yaml`
**ConfigMap**: `prometheus-config` (namespace: `monitoring`)
**Key Changes**: Port 80 â†’ 4021 for rsolv-platform scraping

### Grafana Configuration
**File**: `RSOLV-infrastructure/shared/monitoring/base/grafana.yaml`
**ConfigMap**: `grafana-dashboards`, `grafana-datasources`
**Dashboard**: `priv/grafana_dashboards/rfc-060-validation-metrics.json`

### Alert Rules
**File**: `config/prometheus/rfc-060-alerts.yml`
**ConfigMap**: `prometheus-rules` (namespace: `monitoring`)
**Key**: `rfc060_alerts.yml`

### PromEx Plugin
**File**: `lib/rsolv/prom_ex/validation_plugin.ex`
**Status**: Configured but no events being emitted
**Events Expected**:
- `[:rsolv, :validation, :complete]`
- `[:rsolv, :validation, :test_generated]`
- `[:rsolv, :mitigation, :complete]`
- `[:rsolv, :mitigation, :trust_score]`

---

## Appendix: Metrics Schema

### Expected RFC-060 Metrics (Once Implemented)

```promql
# Validation execution counter
rsolv_validation_executions_total{
  repo="RSOLV-dev/nodegoat",
  language="javascript",
  framework="vitest",
  status="completed|failed"
}

# Test generation counter
rsolv_validation_test_generated_total{
  repo="RSOLV-dev/nodegoat",
  language="javascript",
  framework="vitest"
}

# Validation duration histogram
rsolv_validation_duration_milliseconds_bucket{
  repo="RSOLV-dev/nodegoat",
  language="javascript",
  framework="vitest",
  le="1000|5000|10000|30000|60000|120000|300000|+Inf"
}

# Mitigation execution counter
rsolv_mitigation_executions_total{
  repo="RSOLV-dev/nodegoat",
  language="javascript",
  framework="vitest",
  status="completed|failed"
}

# Trust score histogram
rsolv_mitigation_trust_score_value_bucket{
  repo="RSOLV-dev/nodegoat",
  language="javascript",
  framework="vitest",
  le="0|25|50|60|70|80|90|95|100|+Inf"
}
```

---

## Related Documentation

- [RFC-060 Completion Report](RFCs/RFC-060-COMPLETION-REPORT.md)
- [RFC-060-AMENDMENT-001](RFCs/RFC-060-AMENDMENT-001-TEST-INTEGRATION.md)
- [ADR-031: AST Integration Architecture](ADRs/ADR-031-AST-TEST-INTEGRATION.md)
- [Validation Troubleshooting Guide](RSOLV-action/docs/VALIDATION-TROUBLESHOOTING.md)
- [Integration Patterns](RSOLV-action/docs/INTEGRATION-PATTERNS.md)
- [Not-Validated Runbook](RSOLV-action/docs/NOT-VALIDATED-RUNBOOK.md)

---

## Summary

**Infrastructure Status**: âœ… Healthy and operational

**Critical Gap**: âŒ RFC-060 telemetry events not implemented

**Next Steps**:
1. Implement backend API telemetry (2-4 hours)
2. Test and verify metrics collection
3. Plan frontend push metrics for comprehensive workflow visibility

**Impact**: Once telemetry is implemented, full monitoring stack will be functional for RFC-060 validation and mitigation tracking.

---

**Report Version**: 1.0
**Last Updated**: 2025-10-15
**Next Review**: After telemetry implementation (Week 2)
