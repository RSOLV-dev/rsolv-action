defmodule RsolvWeb.Api.V1.VulnerabilityValidationController do
  @moduledoc """
  Controller for validating detected vulnerabilities using AST analysis.
  Part of RFC-036: Server-Side AST Validation Before Issue Creation.

  This controller receives vulnerabilities detected by regex patterns and
  validates them using AST analysis to reduce false positives.
  """

  use RsolvWeb, :controller

  alias Rsolv.Cache.ValidationCache
  alias RsolvWeb.Telemetry.ValidationTelemetry
  alias RsolvWeb.Api.V1.FilePathClassifier
  alias RsolvWeb.Api.V1.SafePatternDetector
  alias RsolvWeb.Api.V1.TaintAnalyzer
  alias Rsolv.AST.CommentDetector

  require Logger

  plug RsolvWeb.Plugs.ApiAuthentication

  def validate(conn, params) do
    start_time = System.monotonic_time(:millisecond)
    customer = conn.assigns.customer

    with {:ok, vulnerabilities} <- validate_request(params) do
      # Process vulnerabilities
      # OpenAPI creates a struct, so use struct field access
      files =
        cond do
          is_struct(params) -> Map.get(params, :files, %{})
          is_map(params) -> params[:files] || params["files"] || %{}
          true -> %{}
        end

      validated_results =
        validate_vulnerabilities(
          vulnerabilities,
          files
        )

      # Calculate stats
      stats = calculate_stats(validated_results)

      # Track cache statistics
      cache_stats = ValidationCache.get_stats()

      # Build response
      response = %{
        validated: validated_results,
        stats: stats,
        cache_stats: cache_stats
      }

      # Emit telemetry events
      ValidationTelemetry.emit_validation_request(
        start_time,
        response,
        Map.get(cache_stats, "cache_hits", 0) > 0
      )

      ValidationTelemetry.emit_false_positive(response, customer.id)

      json(conn, response)
    else
      {:error, :invalid_request} = error ->
        ValidationTelemetry.emit_validation_error(start_time, error)

        conn
        |> put_status(400)
        |> json(%{error: "Invalid request format"})
    end
  end

  defp validate_request(%{vulnerabilities: vulnerabilities})
       when is_list(vulnerabilities) do
    {:ok, vulnerabilities}
  end

  defp validate_request(%{"vulnerabilities" => vulnerabilities})
       when is_list(vulnerabilities) do
    {:ok, vulnerabilities}
  end

  defp validate_request(_), do: {:error, :invalid_request}

  defp validate_vulnerabilities(vulnerabilities, files) do
    # Track which results we've already computed to handle internal duplicates
    cache_map = %{}

    {validated_results, _final_cache_map} =
      Enum.map_reduce(vulnerabilities, cache_map, fn vuln, acc_cache ->
        # Use standardized "file" field
        file = vuln["file"]
        file_info = Map.get(files, file, %{})

        file_content =
          case file_info do
            %{"content" => content} -> content
            content when is_binary(content) -> content
            _ -> ""
          end

        cache_key = ValidationCache.generate_key(vuln, file_content)

        # Check if we've already processed this in the current batch
        case Map.get(acc_cache, cache_key) do
          nil ->
            # Not in local cache, check global cache
            result =
              case ValidationCache.get(cache_key) do
                {:ok, cached_result} ->
                  # Found in global cache
                  ValidationTelemetry.emit_cache_hit()
                  Map.put(cached_result, "fromCache", true)

                :error ->
                  # Not in cache, compute result
                  ValidationTelemetry.emit_cache_miss()
                  computed_result = validate_single_vulnerability(vuln, files)
                  # Store in cache for future requests
                  ValidationCache.put(cache_key, computed_result)
                  Map.put(computed_result, "fromCache", false)
              end

            # Store in local cache for this batch
            {result, Map.put(acc_cache, cache_key, result)}

          cached_result ->
            # Found in local cache (duplicate in same batch)
            ValidationCache.increment_internal_hits()
            {Map.put(cached_result, "fromCache", true), acc_cache}
        end
      end)

    validated_results
  end

  defp validate_single_vulnerability(vuln, files) do
    # Use standardized "file" field - handle both string and atom keys
    file = vuln[:file] || vuln["file"]
    file_info = Map.get(files, file)

    file_content =
      case file_info do
        %{"content" => content} -> content
        content when is_binary(content) -> content
        _ -> nil
      end

    vuln_id = vuln[:id] || vuln["id"]

    if file_content do
      # Perform AST validation - always returns {:ok, result}
      {:ok, result} = perform_ast_validation(vuln, file_content)
      result
    else
      # No file content, can't validate
      %{
        "id" => vuln_id,
        "isValid" => true,
        "confidence" => 0.5,
        "reason" => "File content unavailable"
      }
    end
  end

  defp perform_ast_validation(vuln, file_content) do
    # Handle both string and atom keys for vuln struct
    file = vuln[:file] || vuln["file"]
    code = vuln[:code] || vuln["code"]
    line = vuln[:line] || vuln["line"]
    vuln_type = vuln[:type] || vuln["type"]
    vuln_id = vuln[:id] || vuln["id"]

    # Step 1: Check file path classification
    file_classification = FilePathClassifier.classify(file)
    confidence_multiplier = FilePathClassifier.confidence_multiplier(file_classification)

    # Step 2: Check for safe patterns
    vulnerability_type = vuln_type |> to_vulnerability_atom()
    language = detect_language(file)

    is_safe_pattern =
      SafePatternDetector.is_safe_pattern?(
        vulnerability_type,
        code,
        %{language: language}
      )

    cond do
      # Check if safe pattern detected
      is_safe_pattern ->
        explanation =
          SafePatternDetector.explain_safety(
            vulnerability_type,
            code,
            %{language: language}
          )

        {:ok,
         %{
           "id" => vuln_id,
           "isValid" => false,
           "confidence" => 0.1 * confidence_multiplier,
           "reason" => "Safe pattern detected: #{explanation}",
           "astContext" => %{
             "inUserInputFlow" => false,
             "hasValidation" => true,
             "fileClassification" => to_string(file_classification),
             "safePattern" => true
           }
         }}

      # Check if this is in a comment
      CommentDetector.in_comment?(code, file_content, line) ->
        {:ok,
         %{
           "id" => vuln_id,
           "isValid" => false,
           "confidence" => 0.1 * confidence_multiplier,
           "reason" => "Code found in comment",
           "astContext" => %{
             "inUserInputFlow" => false,
             "hasValidation" => false,
             "fileClassification" => to_string(file_classification)
           }
         }}

      # Check if this is in a string literal (false positive)
      is_in_string_literal?(code, file_content, line) ->
        {:ok,
         %{
           "id" => vuln_id,
           "isValid" => false,
           "confidence" => 0.1 * confidence_multiplier,
           "reason" => "Code found in string literal",
           "astContext" => %{
             "inUserInputFlow" => false,
             "hasValidation" => false,
             "fileClassification" => to_string(file_classification)
           }
         }}

      # For real vulnerabilities, perform deeper analysis
      true ->
        {:ok, context} = analyze_vulnerability_context(vuln, file_content)
        base_confidence = calculate_confidence(context)
        adjusted_confidence = base_confidence * confidence_multiplier

        # Apply filtering for vendor and test files with low confidence
        should_filter =
          FilePathClassifier.should_filter?(file_classification, adjusted_confidence)

        {:ok,
         %{
           "id" => vuln_id,
           "isValid" => not should_filter,
           "confidence" => adjusted_confidence,
           "reason" =>
             if(should_filter,
               do: "Filtered: #{file_classification} file with low confidence",
               else: nil
             ),
           "astContext" =>
             Map.merge(context, %{
               "fileClassification" => to_string(file_classification)
             })
         }}
    end
  end

  defp is_in_string_literal?(code, file_content, line_number) do
    lines = String.split(file_content, "\n")
    # Handle both 0-based and 1-based line numbers
    actual_line_number = if line_number == 0, do: 1, else: line_number
    line = Enum.at(lines, actual_line_number - 1, "")

    # Check various string literal patterns
    cond do
      # Direct string assignment patterns
      String.match?(line, ~r/=\s*["'`].*eval.*["'`]/) and
          String.trim(line) == code ->
        true

      # Check if the code includes quotes as part of the pattern
      # e.g., code = "const warning = 'Never use eval()'"
      String.match?(code, ~r/["'`].*eval.*["'`]/) ->
        # It's a string literal assignment
        true

      # Template literal check
      String.contains?(line, "`") and String.contains?(line, "eval") and
          not String.match?(line, ~r/eval\s*\(/) ->
        true

      # Python/Ruby string patterns
      String.match?(line, ~r/=\s*["'].*exec.*["']/) ->
        true

      true ->
        false
    end
  end

  defp analyze_vulnerability_context(vuln, file_content) do
    # Use TaintAnalyzer for comprehensive taint analysis
    # Handle both string and atom keys
    line_number = vuln[:line] || vuln["line"] || vuln[:lineNumber] || vuln["lineNumber"] || 1
    code = vuln[:code] || vuln["code"]
    taint_analysis = TaintAnalyzer.analyze(code, file_content, line_number)

    # Build context from taint analysis
    context = %{
      "inUserInputFlow" => taint_analysis.direct_input || taint_analysis.tainted_flow,
      "hasValidation" => taint_analysis.has_sanitization,
      "taintLevel" => taint_analysis.taint_level,
      "taintConfidence" => taint_analysis.confidence,
      "directInput" => taint_analysis.direct_input,
      "taintedFlow" => taint_analysis.tainted_flow,
      "suspiciousName" => taint_analysis.suspicious_name,
      "hasSanitization" => taint_analysis.has_sanitization
    }

    # Add hops information if available
    context =
      if Map.has_key?(taint_analysis, :hops) do
        Map.put(context, "taintHops", taint_analysis.hops)
      else
        context
      end

    {:ok, context}
  end

  defp calculate_confidence(context) do
    # Use taint confidence from TaintAnalyzer if available
    # This provides multi-level confidence based on taint analysis
    if Map.has_key?(context, "taintConfidence") do
      context["taintConfidence"]
    else
      # Fallback to simple calculation if taint analysis not available
      if context["inUserInputFlow"] do
        0.95
      else
        0.8
      end
    end
  end

  defp calculate_stats(validated_results) do
    total = length(validated_results)
    validated = Enum.count(validated_results, fn r -> r["isValid"] == true end)
    rejected = total - validated

    %{
      "total" => total,
      "validated" => validated,
      "rejected" => rejected
    }
  end

  # Helper function to convert vulnerability type string to atom
  defp to_vulnerability_atom(type) when is_binary(type) do
    type
    |> String.downcase()
    |> String.replace("-", "_")
    |> String.to_atom()
  end

  defp to_vulnerability_atom(type), do: type

  # Helper function to detect language from file extension
  defp detect_language(file) when is_binary(file) do
    cond do
      String.ends_with?(file, [".js", ".jsx", ".ts", ".tsx", ".mjs"]) -> "javascript"
      String.ends_with?(file, [".py"]) -> "python"
      String.ends_with?(file, [".rb", ".erb"]) -> "ruby"
      String.ends_with?(file, [".php"]) -> "php"
      String.ends_with?(file, [".ex", ".exs"]) -> "elixir"
      String.ends_with?(file, [".go"]) -> "go"
      String.ends_with?(file, [".java"]) -> "java"
      String.ends_with?(file, [".rs"]) -> "rust"
      # Default to JavaScript
      true -> "javascript"
    end
  end

  defp detect_language(_), do: "javascript"
end
